# CMPT-318

## Final Project

Our dependence on digital systems in our everyday lives introduces demand for better protection of these systems. With cyberthreats such as advanced persistent threats and attacks to existing vulnerabilities becoming more prevalent, our critical infrastructure systems become increasingly at risk. One method of providing protection and mitigating attacks is the use of automated control processes. These processes not only increase efficiency and quality of the service they provide but also continuously monitor the operating conditions of systems and machinery. Real-time data collected from the automated control process monitoring is vital for early threat detection and could potentially aid in mitigating the impact of attacks. 

This term project emulates threat detection in a dataset of electric energy consumption over multiple years with seven variables collected each minute. Through the use of feature engineering and Hidden Markov Model training and testing, a model was created to detect anomalies in the power consumption data that could be representative of real cyberthreats. Moving on to Feature Engineering, Principal Component Analysis (PCA) was performed to extract the two most statistically significant variables from the data set to be used in the HMM training and testing.  The results of the PCA test concluded that Global intensity and Global active power were the two most statistically significant variables in the dataset. Subsequently, HMM Training and Testing were performed. HMMs were run on a time window between 18:00 and 21:00 on Tuesdays. From testing a range of number of states, 16 performed the best due to its balance between high log-likelihood and BIC value. The HMMs with 16 states resulted in a log-likelihood of -0.2541 and -0.7364 for training and testing respectively. These scores act as a baseline for what is expected from non-anomalous data. Following the findings from the HMM section, the performance of the model was tested against three datasets (of the same structure). This resulted in log-likelihoods of -1.695106, -2.148274, -1.695131 for the first, second and third set. The discrepancy of log-likelihoods between the training/testing likelihoods from the non-anomalous data and the likelihoods from the new datasets was large enough to determine that the newly tested datasets contained anomalies where the second dataset is more anomalous than the other two.
